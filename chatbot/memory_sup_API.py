# memory_sup_API.py
import faiss
import numpy as np
import os
import pickle
import torch
from sentence_transformers import SentenceTransformer
import re
import json

# -------------------- è®€å–è¨­å®šæª” --------------------
CONFIG_PATH = "config.json"
DEFAULT_CFG = {
    # å‘é‡æ¨¡åž‹/ç¶­åº¦
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
    "embedding_dim": 384,

    # æª”æ¡ˆè·¯å¾‘
    "text_index_file": "chat_faiss.idx",
    "text_memories_pickle": "chat_text_memories.pkl",
    "text_memories_persistent": "persistent_memories.txt",
    "structured_memory_file": "structured_memories.pkl",

    # åå¥½æª¢ç´¢é è¨­é–€æª»ï¼ˆå¯è¢« search_preferences å‘¼å«æ™‚è¦†å¯«ï¼‰
    "preference_distance_threshold": 1.03
}

if os.path.exists(CONFIG_PATH):
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        CFG = {**DEFAULT_CFG, **json.load(f)}
else:
    CFG = DEFAULT_CFG


def format_vector_snippet(vector, n=5):
    if not isinstance(vector, np.ndarray):
        vector = np.array(vector)
    if vector.ndim > 1:
        vector = vector.flatten()
    if vector.size == 0:
        return "[]"
    if vector.size <= 2 * n:
        return f"{vector.tolist()}"
    first_part = [f"{x:.4f}" for x in vector[:n]]
    last_part = [f"{x:.4f}" for x in vector[-n:]]
    return f"[{', '.join(first_part)}, ..., {', '.join(last_part)}]"


class MemoryManager:
    def __init__(self,
                 model_name=None,
                 embedding_dim=None,
                 index_file=None,
                 memories_pickle_file=None,
                 persistent_text_file=None,
                 structured_memory_file=None,
                 embedding_fn=None):
        """
        åƒæ•¸ç•™ç©ºæ™‚æœƒè®€å– config.jsonï¼š
          - model_name â†’ CFG["embedding_model"]
          - embedding_dim â†’ CFG["embedding_dim"]
          - index_file â†’ CFG["text_index_file"]
          - memories_pickle_file â†’ CFG["text_memories_pickle"]
          - persistent_text_file â†’ CFG["text_memories_persistent"]
          - structured_memory_file â†’ CFG["structured_memory_file"]
        """
        # ---- å¥—ç”¨è¨­å®šæª”æˆ–è¦†å¯«å€¼
        self.embedding_dim = int(embedding_dim or CFG["embedding_dim"])
        self.index_file = index_file or CFG["text_index_file"]
        self.memories_pickle_file = memories_pickle_file or CFG["text_memories_pickle"]
        self.persistent_text_memories_file = persistent_text_file or CFG["text_memories_persistent"]
        self.structured_memory_file = structured_memory_file or CFG["structured_memory_file"]
        model_name = model_name or CFG["embedding_model"]

        # åå¥½æª¢ç´¢é–€æª»ï¼ˆé è¨­å€¼ï¼Œå¯åœ¨ search_preferences å‘¼å«æ™‚è¦†å¯«ï¼‰
        self.default_pref_threshold = float(CFG.get("preference_distance_threshold", 1.03))

        print("ðŸš€ åˆå§‹åŒ–è¨˜æ†¶ç®¡ç†å™¨ (è®€å– config.json)...")
        print(f"â€¢ model_name={model_name}")
        print(f"â€¢ embedding_dim={self.embedding_dim}")
        print(f"â€¢ index_file={self.index_file}")
        print(f"â€¢ memories_pickle_file={self.memories_pickle_file}")
        print(f"â€¢ persistent_text_memories_file={self.persistent_text_memories_file}")
        print(f"â€¢ structured_memory_file={self.structured_memory_file}")

        # âœ… çµæ§‹åŒ–è¨˜æ†¶ï¼šåƒ…ã€Œåå­—ã€å›ºå®šè¼¸å‡ºï¼›å…¶é¤˜èµ°å‘é‡æª¢ç´¢
        self.structured_memory = {
            "åå­—": None,
            "èˆˆè¶£": set(),
            "å–œå¥½": set(),
            "åŽ­æƒ¡": set(),
            "ç”Ÿæ—¥": None
        }

        # åµŒå…¥æ¨¡åž‹
        if embedding_fn is None:
            try:
                self.embed_model = SentenceTransformer(model_name)
                if torch.cuda.is_available():
                    self.embed_model = self.embed_model.to(torch.device("cuda"))
                print(f"âœ… åµŒå…¥æ¨¡åž‹ '{model_name}' è¼‰å…¥æˆåŠŸã€‚")
            except Exception as e:
                print(f"âŒ åµŒå…¥æ¨¡åž‹è¼‰å…¥å¤±æ•—: {e}")
                raise
        else:
            print("âœ… ä½¿ç”¨å¤–éƒ¨æä¾›çš„ embedding functionï¼ˆä¾‹å¦‚ OpenAI Embedding APIï¼‰")
            self.embedding_fn = embedding_fn

        # ä¸€èˆ¬æ–‡å­—è¨˜æ†¶ï¼ˆèªžæ„æª¢ç´¢ï¼‰
        self.text_memories = []
        self.index = faiss.IndexFlatL2(self.embedding_dim)

        self._load_or_rebuild_from_persistent_file()
        self._load_structured_memories()

        # âœ… åå¥½ç´¢å¼•ï¼ˆèˆˆè¶£/å–œå¥½/åŽ­æƒ¡/ç”Ÿæ—¥ï¼‰
        self._init_preference_index()

    # ------------------ çµæ§‹åŒ–è¨˜æ†¶ ------------------
    def _load_structured_memories(self):
        if os.path.exists(self.structured_memory_file):
            try:
                with open(self.structured_memory_file, 'rb') as f:
                    self.structured_memory = pickle.load(f)
                # ä¿è­‰é›†åˆåž‹åˆ¥
                for k in ["èˆˆè¶£", "å–œå¥½", "åŽ­æƒ¡"]:
                    if not isinstance(self.structured_memory.get(k), set):
                        self.structured_memory[k] = set(self.structured_memory.get(k) or [])
                print(f"âœ… å·²è¼‰å…¥æ ¼å¼åŒ–è¨˜æ†¶ï¼š{self.structured_memory}")
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•è®€å–æ ¼å¼åŒ–è¨˜æ†¶: {e}")

    def update_structured_memory(self, text):
        patterns = {
            "åå­—": r"(?:æˆ‘å«|æˆ‘çš„åå­—æ˜¯)([\u4e00-\u9fa5A-Za-zÂ·ï¼Ž\s]{2,15})",
            "èˆˆè¶£": r"(?:æˆ‘çš„èˆˆè¶£æ˜¯|æˆ‘(çš„)?èˆˆè¶£åŒ…æ‹¬|æˆ‘å–œæ­¡.*?çš„æ´»å‹•æ˜¯)([^ã€‚,\s]{2,15})",
            "å–œå¥½": r"(?:æˆ‘å–œæ­¡|æˆ‘å¾ˆå–œæ­¡)([^ã€‚,\s]{2,15})",
            "åŽ­æƒ¡": r"(?:æˆ‘è¨ŽåŽ­|æˆ‘ä¸å–œæ­¡)([^ã€‚,\s]{2,15})",
            "ç”Ÿæ—¥": r"æˆ‘çš„ç”Ÿæ—¥æ˜¯(\d{1,2}[æœˆ/-]\d{1,2}[æ—¥]?)"
        }
        blacklist = {"çš„", "çš„æ±è¥¿", "å•¦", "å–”", "å—¯", "æ±è¥¿", "é‚£å€‹", "é€™å€‹", "å§", "è€¶", "å•¦å•¦", "XDD", "XD", "å“ˆå“ˆ"}

        updated = False
        updated_pref = False

        for key, pattern in patterns.items():
            match = re.search(pattern, text)
            if match:
                value = match.group(1).strip()
                if len(value) < 2 or value in blacklist:
                    print(f"âš ï¸ æ“·å–çµæžœéŽçŸ­æˆ–åœ¨é»‘åå–®ä¸­ï¼Œç•¥éŽï¼š{value}")
                    continue

                if key in ["åå­—", "ç”Ÿæ—¥"]:
                    self.structured_memory[key] = value
                    print(f"ðŸ§¾ æ ¼å¼åŒ–è¨˜æ†¶æ›´æ–°: {key} âžœ {value}")
                    if key == "ç”Ÿæ—¥":
                        updated_pref = True
                else:
                    if key not in self.structured_memory or not isinstance(self.structured_memory[key], set):
                        self.structured_memory[key] = set()
                    self.structured_memory[key].add(value)
                    print(f"ðŸ§¾ æ ¼å¼åŒ–è¨˜æ†¶æ›´æ–°: {key} âžœ {value}")
                    updated_pref = True

                updated = True
                break  # æ¯æ¬¡åƒ…æ›´æ–°ä¸€ç­†

        if updated:
            print(f"ðŸ“Œ åµæ¸¬åˆ°æ ¼å¼åŒ–è¨˜æ†¶ï¼š{self.structured_memory}")
            # è½ç›¤
            try:
                with open(self.structured_memory_file, 'wb') as f:
                    pickle.dump(self.structured_memory, f)
            except Exception as e:
                print(f"âš ï¸ å„²å­˜æ ¼å¼åŒ–è¨˜æ†¶å¤±æ•—ï¼š{e}")

            # è‹¥åå¥½ç›¸é—œæœ‰æ›´æ–°ï¼Œé‡å»ºåå¥½ç´¢å¼•
            if updated_pref:
                self._rebuild_preferences_index()

    def get_structured_memory_prompt(self, fixed_fields=None):
        """
        âœ… åªè¼¸å‡ºå›ºå®šèƒŒæ™¯ï¼ˆé è¨­ç‚ºåå­—ï¼‰ã€‚å…¶é¤˜æ¬„ä½æ”¹ç”±èªžæ„è§¸ç™¼æª¢ç´¢ã€‚
        fixed_fields: æƒ³å›ºå®šè¼¸å‡ºçš„æ¬„ä½é›†åˆï¼Œé è¨­åƒ… {"åå­—"}
        """
        if fixed_fields is None:
            fixed_fields = {"åå­—"}
        lines = []
        for field in fixed_fields:
            val = self.structured_memory.get(field)
            if isinstance(val, set):
                if val:
                    lines.append(f"- {field}ï¼š{', '.join(sorted(val))}")
            elif val:
                lines.append(f"- {field}ï¼š{val}")
        return "ä»¥ä¸‹æ˜¯æˆ‘å·²çŸ¥çš„ä½¿ç”¨è€…åŸºæœ¬è³‡è¨Šï¼š\n" + "\n".join(lines) + "\n" if lines else ""

    # ------------------ ä¸€èˆ¬æ–‡å­—è¨˜æ†¶ï¼ˆèªžæ„æª¢ç´¢ï¼‰ ------------------
    def _load_or_rebuild_from_persistent_file(self):
        self.index.reset()
        self.text_memories = []

        if not os.path.exists(self.persistent_text_memories_file):
            print(f"â„¹ï¸ æŒä¹…è¨˜æ†¶æª”æ¡ˆ '{self.persistent_text_memories_file}' ä¸å­˜åœ¨ã€‚å°‡ä»¥ç©ºè¨˜æ†¶å•Ÿå‹•ã€‚")
            self._save_faiss_and_pkl()
            return

        print(f"ðŸ”„ å¾ž '{self.persistent_text_memories_file}' å®Œæ•´é‡å»ºè¨˜æ†¶...")
        loaded_memories = []
        try:
            with open(self.persistent_text_memories_file, 'r', encoding='utf-8') as f:
                for line in f:
                    mem_text = line.strip()
                    if mem_text:
                        loaded_memories.append(mem_text)

            unique_memories = list(dict.fromkeys(loaded_memories))
            for mem_text in unique_memories:
                self._add_text_to_internal_stores(mem_text, verbose=False)

            self._save_faiss_and_pkl()
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.text_memories)} æ¢è¨˜æ†¶ã€‚")
        except Exception as e:
            print(f"âŒ è¼‰å…¥è¨˜æ†¶æ™‚éŒ¯èª¤: {e}ã€‚å°‡ä»¥ç©ºè¨˜æ†¶å•Ÿå‹•ã€‚")
            self.index.reset()
            self.text_memories = []
            self._save_faiss_and_pkl()

    def _add_text_to_internal_stores(self, text_to_remember, verbose=True):
        if not text_to_remember.strip() or text_to_remember in self.text_memories:
            return False
        try:
            if hasattr(self, 'embedding_fn') and self.embedding_fn:
                embedding = np.array([self.embedding_fn(text_to_remember)], dtype=np.float32)
            else:
                embedding = self.embed_model.encode([text_to_remember], convert_to_numpy=True, normalize_embeddings=True)
                embedding = embedding.astype('float32')

            if embedding.shape[1] != self.embedding_dim:
                print(f"âŒ åµŒå…¥ç¶­åº¦éŒ¯èª¤ for '{text_to_remember[:30]}...'")
                return False

            if verbose:
                print(f"   å‘é‡åŒ– \"{text_to_remember[:30]}...\" (ç¶­åº¦: {embedding.shape}): {format_vector_snippet(embedding)}")

            self.index.add(embedding)
            self.text_memories.append(text_to_remember)
            return True
        except Exception as e:
            print(f"âŒ æ–°å¢žè¨˜æ†¶æ™‚å‡ºéŒ¯: {e}")
            return False

    def add_memory(self, text_to_remember):
        if not text_to_remember.strip():
            print("âš ï¸ ç©ºç™½è¨˜æ†¶ï¼Œå·²å¿½ç•¥ã€‚")
            return
        if text_to_remember in self.text_memories:
            print(f"â„¹ï¸ è¨˜æ†¶å·²å­˜åœ¨: \"{text_to_remember[:50]}...\"")
            return

        print(f"ðŸ§  æ–°è¨˜æ†¶åµŒå…¥: \"{text_to_remember[:50]}...\"")
        if self._add_text_to_internal_stores(text_to_remember, verbose=True):
            try:
                with open(self.persistent_text_memories_file, 'a', encoding='utf-8') as f:
                    f.write(text_to_remember + "\n")
                print(f"ðŸ“ å·²å„²å­˜è‡³ '{self.persistent_text_memories_file}'")
                self._save_faiss_and_pkl()
                print(f"âœ… æ–°å¢žæˆåŠŸï¼Œå…± {self.index.ntotal} æ¢è¨˜æ†¶ã€‚")
            except Exception as e:
                print(f"âŒ å„²å­˜è¨˜æ†¶æ™‚éŒ¯èª¤: {e}")
        else:
            print(f"âš ï¸ è¨˜æ†¶æœªå„²å­˜: \"{text_to_remember[:50]}...\"")

    def _save_faiss_and_pkl(self):
        try:
            if self.index.ntotal == len(self.text_memories):
                faiss.write_index(self.index, self.index_file)
                with open(self.memories_pickle_file, 'wb') as f:
                    pickle.dump(self.text_memories, f)
            else:
                print(f"âš ï¸ FAISS èˆ‡æ–‡å­—è¨˜æ†¶æ•¸é‡ä¸ç¬¦ï¼Œæœªå„²å­˜ã€‚")
        except Exception as e:
            print(f"âŒ å„²å­˜éŒ¯èª¤: {e}")

    def save_memories_on_exit(self):
        print("ðŸ’¾ å„²å­˜é›¢é–‹å‰ç‹€æ…‹...")
        self._save_faiss_and_pkl()
        with open(self.structured_memory_file, 'wb') as f:
            pickle.dump(self.structured_memory, f)
        print(f"âœ… å…±å„²å­˜ {self.index.ntotal} æ¢è¨˜æ†¶ã€‚æ ¼å¼åŒ–è¨˜æ†¶æ¬„ä½ {len(self.structured_memory)} é …ã€‚")

    def search_memories(self, query_text, k=3):
        if not query_text.strip() or self.index.ntotal == 0:
            return [], None, []
        try:
            if hasattr(self, 'embedding_fn') and self.embedding_fn:
                query_embedding = np.array([self.embedding_fn(query_text)], dtype=np.float32)
            else:
                query_embedding = self.embed_model.encode([query_text], convert_to_numpy=True, normalize_embeddings=True)
                query_embedding = query_embedding.astype('float32')

            if query_embedding.shape[1] != self.embedding_dim:
                print(f"âŒ æŸ¥è©¢åµŒå…¥ç¶­åº¦ä¸ç¬¦ã€‚")
                return [], None, []

            actual_k = min(k, self.index.ntotal)
            distances, indices = self.index.search(query_embedding, actual_k)
            retrieved_texts = [self.text_memories[i] for i in indices[0]]
            return retrieved_texts, query_embedding, distances[0]
        except Exception as e:
            print(f"âŒ æœå°‹è¨˜æ†¶éŒ¯èª¤: {e}")
            return [], None, []

    def get_total_memories(self):
        return self.index.ntotal

    def reload_external_memories(self):
        print(f"ðŸ”„ é‡æ–°è¼‰å…¥ '{self.persistent_text_memories_file}'...")
        self._load_or_rebuild_from_persistent_file()
        self._load_structured_memories()
        self._rebuild_preferences_index()

    # ------------------ åå¥½ç´¢å¼•ï¼ˆèˆˆè¶£/å–œå¥½/åŽ­æƒ¡/ç”Ÿæ—¥ï¼‰ ------------------
    def _init_preference_index(self):
        self.pref_index = faiss.IndexFlatL2(self.embedding_dim)
        self.pref_items = []  # list of {"type":é¡žåˆ¥, "text":å€¼, "surface":æª¢ç´¢å¥}
        self._rebuild_preferences_index()

    def _rebuild_preferences_index(self):
        self.pref_index.reset()
        self.pref_items = []

        def add_items(t):
            vals = self.structured_memory.get(t)
            if t == "ç”Ÿæ—¥":
                if vals:
                    self.pref_items.append({"type": "ç”Ÿæ—¥", "text": vals, "surface": f"æˆ‘çš„ç”Ÿæ—¥æ˜¯{vals}"})
            elif isinstance(vals, set):
                for v in sorted(vals):
                    v = v.strip()
                    if not v:
                        continue
                    if t == "å–œå¥½":
                        surface = f"æˆ‘å–œæ­¡{v}"
                    elif t == "åŽ­æƒ¡":
                        surface = f"æˆ‘ä¸å–œæ­¡{v}"
                    else:  # èˆˆè¶£
                        surface = f"æˆ‘çš„èˆˆè¶£æ˜¯{v}"
                    self.pref_items.append({"type": t, "text": v, "surface": surface})

        add_items("èˆˆè¶£")
        add_items("å–œå¥½")
        add_items("åŽ­æƒ¡")
        add_items("ç”Ÿæ—¥")

        if not self.pref_items:
            return

        sentences = [it["surface"] for it in self.pref_items]
        if hasattr(self, 'embedding_fn') and self.embedding_fn:
            embs = np.array([self.embedding_fn(s) for s in sentences], dtype=np.float32)
        else:
            embs = self.embed_model.encode(sentences, convert_to_numpy=True, normalize_embeddings=True).astype('float32')
        self.pref_index.add(embs)
        print(f"âœ… åå¥½ç´¢å¼•å»ºç«‹å®Œæˆï¼Œå…± {len(self.pref_items)} æ¢ã€‚")

    def search_preferences(self, query_text, k=5, distance_threshold=None, types=None):
        """
        å›žå‚³èˆ‡ query æœ€ç›¸é—œçš„å€‹äººåå¥½ï¼ˆèˆˆè¶£/å–œå¥½/åŽ­æƒ¡/ç”Ÿæ—¥ï¼‰ã€‚
        types: å¯å‚³é›†åˆ {"å–œå¥½","åŽ­æƒ¡","èˆˆè¶£","ç”Ÿæ—¥"} éŽæ¿¾ï¼›None è¡¨ç¤ºä¸éŽæ¿¾ã€‚
        distance_threshold: None å‰‡ä½¿ç”¨ config çš„é è¨­å€¼ã€‚
        """
        if self.pref_index.ntotal == 0 or not query_text.strip():
            return []

        if distance_threshold is None:
            distance_threshold = self.default_pref_threshold  # è®€ config é è¨­

        # æŸ¥è©¢å‘é‡
        if hasattr(self, 'embedding_fn') and self.embedding_fn:
            q = np.array([self.embedding_fn(query_text)], dtype=np.float32)
        else:
            q = self.embed_model.encode([query_text], convert_to_numpy=True, normalize_embeddings=True).astype('float32')

        k = min(k, self.pref_index.ntotal)
        D, I = self.pref_index.search(q, k)
        out = []
        for d, i in zip(D[0], I[0]):
            if i < 0 or i >= len(self.pref_items):
                continue
            item = self.pref_items[i]
            if (types is None) or (item["type"] in types):
                if float(d) <= float(distance_threshold):
                    out.append({"type": item["type"], "text": item["text"], "distance": float(d)})
        return out
